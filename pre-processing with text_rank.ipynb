{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "import contractions\n",
    "import google_list\n",
    "import re\n",
    "import nltk\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '/home/werewolf97/imtech/pro/fulldata/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = Path(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/werewolf97/imtech/pro/fulldata')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_path = Path.joinpath(input_path.parent, \"converted_files\")\n",
    "if not os.path.exists(converted_path):\n",
    "    os.mkdir(converted_path)\n",
    "#print(type(self.input_path.as_posix()))\n",
    "files = input_path.rglob(f\"*.pdf\")\n",
    "#print(\"Files found: {0}\".format(files))\n",
    "exts = [\".pdf\", \".txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in input_path.rglob('*'):\n",
    "#     path = dirc+file\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read().replace('\\n', ' ')\n",
    "    if content is not None:\n",
    "        data = [f'{file.parent.name}_{file.name}', content]\n",
    "        text_data.append(data)\n",
    "text_corpus = pd.DataFrame(text_data, columns=['resource_id', 'description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = text_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['full_text'] = \"\"\n",
    "corpus['full_text'] = corpus['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resource_id</th>\n",
       "      <th>description</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fulldata_LNch7.txt</td>\n",
       "      <td>7 Connectivity  Frank Kammer and Hanjo T¨aubig...</td>\n",
       "      <td>7 Connectivity  Frank Kammer and Hanjo T¨aubig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fulldata_Mandate2.txt</td>\n",
       "      <td>Network Science   for the Web  Mandate - 2: St...</td>\n",
       "      <td>Network Science   for the Web  Mandate - 2: St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fulldata_LNch3.txt</td>\n",
       "      <td>3 Centrality Indices Dirk Kosch¨utzki,∗ Kathar...</td>\n",
       "      <td>3 Centrality Indices Dirk Kosch¨utzki,∗ Kathar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fulldata_SocialLearningL2.txt</td>\n",
       "      <td>Social Learning in Networks       ...</td>\n",
       "      <td>Social Learning in Networks       ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fulldata_NCMch10.txt</td>\n",
       "      <td>CHAPTER 10  Matching Markets  We have now seen...</td>\n",
       "      <td>CHAPTER 10  Matching Markets  We have now seen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>fulldata_NCMch14.txt</td>\n",
       "      <td>CHAPTER 14  Link Analysis and Web Search  14.1...</td>\n",
       "      <td>CHAPTER 14  Link Analysis and Web Search  14.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>fulldata_LNch12.txt</td>\n",
       "      <td>12 Network Comparison  Michael Baur and Marc B...</td>\n",
       "      <td>12 Network Comparison  Michael Baur and Marc B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>fulldata_LNch1.txt</td>\n",
       "      <td>1 Introduction  Ulrik Brandes and Thomas Erleb...</td>\n",
       "      <td>1 Introduction  Ulrik Brandes and Thomas Erleb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>fulldata_NetworkCENTRALITYL2.txt</td>\n",
       "      <td>Shapley Value Recap     Cooperating Agents: A...</td>\n",
       "      <td>Shapley Value Recap     Cooperating Agents: A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>fulldata_NCMch7.txt</td>\n",
       "      <td>CHAPTER 7  Evolutionary Game Theory  In Chapte...</td>\n",
       "      <td>CHAPTER 7  Evolutionary Game Theory  In Chapte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         resource_id  \\\n",
       "0                 fulldata_LNch7.txt   \n",
       "1              fulldata_Mandate2.txt   \n",
       "2                 fulldata_LNch3.txt   \n",
       "3      fulldata_SocialLearningL2.txt   \n",
       "4               fulldata_NCMch10.txt   \n",
       "..                               ...   \n",
       "62              fulldata_NCMch14.txt   \n",
       "63               fulldata_LNch12.txt   \n",
       "64                fulldata_LNch1.txt   \n",
       "65  fulldata_NetworkCENTRALITYL2.txt   \n",
       "66               fulldata_NCMch7.txt   \n",
       "\n",
       "                                          description  \\\n",
       "0   7 Connectivity  Frank Kammer and Hanjo T¨aubig...   \n",
       "1   Network Science   for the Web  Mandate - 2: St...   \n",
       "2   3 Centrality Indices Dirk Kosch¨utzki,∗ Kathar...   \n",
       "3               Social Learning in Networks       ...   \n",
       "4   CHAPTER 10  Matching Markets  We have now seen...   \n",
       "..                                                ...   \n",
       "62  CHAPTER 14  Link Analysis and Web Search  14.1...   \n",
       "63  12 Network Comparison  Michael Baur and Marc B...   \n",
       "64  1 Introduction  Ulrik Brandes and Thomas Erleb...   \n",
       "65  Shapley Value Recap     Cooperating Agents: A...   \n",
       "66  CHAPTER 7  Evolutionary Game Theory  In Chapte...   \n",
       "\n",
       "                                            full_text  \n",
       "0   7 Connectivity  Frank Kammer and Hanjo T¨aubig...  \n",
       "1   Network Science   for the Web  Mandate - 2: St...  \n",
       "2   3 Centrality Indices Dirk Kosch¨utzki,∗ Kathar...  \n",
       "3               Social Learning in Networks       ...  \n",
       "4   CHAPTER 10  Matching Markets  We have now seen...  \n",
       "..                                                ...  \n",
       "62  CHAPTER 14  Link Analysis and Web Search  14.1...  \n",
       "63  12 Network Comparison  Michael Baur and Marc B...  \n",
       "64  1 Introduction  Ulrik Brandes and Thomas Erleb...  \n",
       "65  Shapley Value Recap     Cooperating Agents: A...  \n",
       "66  CHAPTER 7  Evolutionary Game Theory  In Chapte...  \n",
       "\n",
       "[67 rows x 3 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_html_tags(text):\n",
    "#     \"\"\"Strips the HTML Tags from the text\"\"\"\n",
    "    try:\n",
    "        soup = BeautifulSoup(text, \"html.parser\")\n",
    "        stripped_text = soup.get_text()\n",
    "    except:\n",
    "        stripped_text = text\n",
    "    return stripped_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accented_chars(text):\n",
    "#         \"\"\"Remove Non UTF-8 Characters from text\"\"\"\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contractions(text, contraction_mapping=contractions.CONTRACTION_MAP):\n",
    "#         \"\"\"Replace contractions in string of text\"\"\"\n",
    "        contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())),\n",
    "                                          flags=re.IGNORECASE | re.DOTALL)\n",
    "\n",
    "        def expand_match(contraction):\n",
    "            match = contraction.group(0)\n",
    "            first_char = match[0]\n",
    "            expanded_contraction = contraction_mapping.get(match) \\\n",
    "                if contraction_mapping.get(match) \\\n",
    "                else contraction_mapping.get(match.lower())\n",
    "            expanded_contraction = first_char + expanded_contraction[1:]\n",
    "            return expanded_contraction\n",
    "\n",
    "        try:\n",
    "            expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "            expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "        except:\n",
    "            expanded_text = text\n",
    "        return expanded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "#         \"\"\"Use the ToktokTokenizer to obtain tokens from the text\"\"\"\n",
    "    tokenizer = nltk.tokenize.toktok.ToktokTokenizer()\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "#         \"\"\"Lemmatize the text using the WordNetLemmatizer\"\"\"\n",
    "    tokenizer = nltk.tokenize.toktok.ToktokTokenizer()\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in tokens])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(text, remove_digits):\n",
    "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords( text):\n",
    "#         \"\"\"Remove Stopwords defined in the stopwords corpus\"\"\"\n",
    "    tokenizer = nltk.tokenize.toktok.ToktokTokenizer()\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    stopword_list = nltk.corpus.stopwords.words('english')\n",
    "    stopword_list.remove('no')\n",
    "    stopword_list.remove('not')\n",
    "    stopword_list.append('cid')\n",
    "    filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    tokens = filtered_tokens\n",
    "    stopword_list = google_list.stopwords\n",
    "    stopword_list.append('cid')\n",
    "#     filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_corpus(corpus):\n",
    "    normalized_corpus = []\n",
    "    counter = 0\n",
    "    for i in range(len(corpus)):\n",
    "        doc = corpus['description'][i]\n",
    "        counter += 1\n",
    "        doc = strip_html_tags(doc)\n",
    "        doc = remove_accented_chars(doc)\n",
    "        doc = expand_contractions(doc)\n",
    "        doc = doc.lower()\n",
    "        doc = re.sub(r'[\\r|\\n|\\r\\n]+', ' ', doc)\n",
    "        doc = lemmatize_text(doc)\n",
    "        special_char_pattern = re.compile(r'([{.(-)!}])')\n",
    "        doc = special_char_pattern.sub(\" \\\\1 \", doc)\n",
    "        doc = remove_special_characters(doc, remove_digits= True)\n",
    "        doc = re.sub(' +', ' ', doc)\n",
    "        doc = remove_stopwords(doc)\n",
    "        normalized_corpus.append(doc)\n",
    "    return normalized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['clean_text'] = normalize_corpus(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(corpus):\n",
    "#         \"\"\"Obtain Tokens for each document in the corpus\"\"\"\n",
    "#     tokenizer = nltk.tokenize.toktok.ToktokTokenizer()\n",
    "    tokenized_doc = []\n",
    "    for doc in corpus:\n",
    "        tokens = tokenize(doc)\n",
    "        filtered_tokens = [w for w in tokens if len(w) > 2]\n",
    "        tokenized_doc.append(filtered_tokens)\n",
    "    return tokenized_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['tokens'] = get_tokens(corpus['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextRank4Keyword():\n",
    "    \"\"\"Extract keywords from text\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.d = 0.85 # damping coefficient, usually is .85\n",
    "        self.min_diff = 1e-5 # convergence threshold\n",
    "        self.steps = 10 # iteration steps\n",
    "        self.node_weight = None # save keywords and its weight\n",
    "\n",
    "    \n",
    "    def set_stopwords(self, stopwords):  \n",
    "        \"\"\"Set stop words\"\"\"\n",
    "        for word in STOP_WORDS.union(set(stopwords)):\n",
    "            lexeme = nlp.vocab[word]\n",
    "            lexeme.is_stop = True\n",
    "    \n",
    "    def sentence_segment(self, doc, candidate_pos, lower):\n",
    "        \"\"\"Store those words only in cadidate_pos\"\"\"\n",
    "        sentences = []\n",
    "        for sent in doc.sents:\n",
    "            selected_words = []\n",
    "            for token in sent:\n",
    "                # Store words only with cadidate POS tag\n",
    "                if token.pos_ in candidate_pos and token.is_stop is False:\n",
    "                    if lower is True:\n",
    "                        selected_words.append(token.text.lower())\n",
    "                    else:\n",
    "                        selected_words.append(token.text)\n",
    "            sentences.append(selected_words)\n",
    "        return sentences\n",
    "        \n",
    "    def get_vocab(self, sentences):\n",
    "        \"\"\"Get all tokens\"\"\"\n",
    "        vocab = OrderedDict()\n",
    "        i = 0\n",
    "        for sentence in sentences:\n",
    "            for word in sentence:\n",
    "                if word not in vocab:\n",
    "                    vocab[word] = i\n",
    "                    i += 1\n",
    "        return vocab\n",
    "    \n",
    "    def get_token_pairs(self, window_size, sentences):\n",
    "        \"\"\"Build token_pairs from windows in sentences\"\"\"\n",
    "        token_pairs = list()\n",
    "        for sentence in sentences:\n",
    "            for i, word in enumerate(sentence):\n",
    "                for j in range(i+1, i+window_size):\n",
    "                    if j >= len(sentence):\n",
    "                        break\n",
    "                    pair = (word, sentence[j])\n",
    "                    if pair not in token_pairs:\n",
    "                        token_pairs.append(pair)\n",
    "        return token_pairs\n",
    "        \n",
    "    def symmetrize(self, a):\n",
    "        return a + a.T - np.diag(a.diagonal())\n",
    "    \n",
    "    def get_matrix(self, vocab, token_pairs):\n",
    "        \"\"\"Get normalized matrix\"\"\"\n",
    "        # Build matrix\n",
    "        vocab_size = len(vocab)\n",
    "        g = np.zeros((vocab_size, vocab_size), dtype='float')\n",
    "        for word1, word2 in token_pairs:\n",
    "            i, j = vocab[word1], vocab[word2]\n",
    "            g[i][j] = 1\n",
    "            \n",
    "        # Get Symmeric matrix\n",
    "        g = self.symmetrize(g)\n",
    "        \n",
    "        # Normalize matrix by column\n",
    "        norm = np.sum(g, axis=0)\n",
    "        g_norm = np.divide(g, norm, where=norm!=0) # this is ignore the 0 element in norm\n",
    "        \n",
    "        return g_norm\n",
    "\n",
    "    \n",
    "    def get_keywords(self, number=20):\n",
    "        \"\"\"Print top number keywords\"\"\"\n",
    "        keywords = []\n",
    "        node_weight = OrderedDict(sorted(self.node_weight.items(), key=lambda t: t[1], reverse=True))\n",
    "        for i, (key, value) in enumerate(node_weight.items()):\n",
    "#             print(key + ' - ' + str(value))\n",
    "            keywords.append(key)\n",
    "            if i > number:\n",
    "                break\n",
    "        return keywords\n",
    "        \n",
    "        \n",
    "    def analyze(self, text, \n",
    "                candidate_pos=['NOUN', 'PROPN'], \n",
    "                window_size=4, lower=False, stopwords=list()):\n",
    "        \"\"\"Main function to analyze text\"\"\"\n",
    "        \n",
    "        # Set stop words\n",
    "        self.set_stopwords(stopwords)\n",
    "        \n",
    "        # Pare text by spaCy\n",
    "        doc = nlp(text)\n",
    "        \n",
    "        # Filter sentences\n",
    "        sentences = self.sentence_segment(doc, candidate_pos, lower) # list of list of words\n",
    "        \n",
    "        # Build vocabulary\n",
    "        vocab = self.get_vocab(sentences)\n",
    "        \n",
    "        # Get token_pairs from windows\n",
    "        token_pairs = self.get_token_pairs(window_size, sentences)\n",
    "        \n",
    "        # Get normalized matrix\n",
    "        g = self.get_matrix(vocab, token_pairs)\n",
    "        \n",
    "        # Initionlization for weight(pagerank value)\n",
    "        pr = np.array([1] * len(vocab))\n",
    "        \n",
    "        # Iteration\n",
    "        previous_pr = 0\n",
    "        for epoch in range(self.steps):\n",
    "            pr = (1-self.d) + self.d * np.dot(g, pr)\n",
    "            if abs(previous_pr - sum(pr))  < self.min_diff:\n",
    "                break\n",
    "            else:\n",
    "                previous_pr = sum(pr)\n",
    "\n",
    "        # Get weight for each node\n",
    "        node_weight = dict()\n",
    "        for word, index in vocab.items():\n",
    "            node_weight[word] = pr[index]\n",
    "        \n",
    "        self.node_weight = node_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj =  TextRank4Keyword()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = []\n",
    "for i in range(len(corpus)): \n",
    "    text = corpus['clean_text'][i]\n",
    "    obj.analyze(text)\n",
    "    a = obj.get_keywords(500)\n",
    "    #     b = corpus['tokens'][i]\n",
    "    #     l = []\n",
    "    #     for i in a:\n",
    "    #         if i in b:\n",
    "    #             l.append(i)\n",
    "    keywords.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['keywords'] = keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resource_id</th>\n",
       "      <th>description</th>\n",
       "      <th>full_text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fulldata_LNch7.txt</td>\n",
       "      <td>7 Connectivity  Frank Kammer and Hanjo T¨aubig...</td>\n",
       "      <td>7 Connectivity  Frank Kammer and Hanjo T¨aubig...</td>\n",
       "      <td>connectivity frank kammer hanjo aubig chapter ...</td>\n",
       "      <td>[connectivity, frank, kammer, hanjo, aubig, ch...</td>\n",
       "      <td>[graph, vertex, g, edge, algorithm, v, connect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fulldata_Mandate2.txt</td>\n",
       "      <td>Network Science   for the Web  Mandate - 2: St...</td>\n",
       "      <td>Network Science   for the Web  Mandate - 2: St...</td>\n",
       "      <td>network science web mandate structural analysi...</td>\n",
       "      <td>[network, science, web, mandate, structural, a...</td>\n",
       "      <td>[graph, node, centrality, game, network, v, me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fulldata_LNch3.txt</td>\n",
       "      <td>3 Centrality Indices Dirk Kosch¨utzki,∗ Kathar...</td>\n",
       "      <td>3 Centrality Indices Dirk Kosch¨utzki,∗ Kathar...</td>\n",
       "      <td>centrality index dirk kosch utzki katharina an...</td>\n",
       "      <td>[centrality, index, dirk, kosch, utzki, kathar...</td>\n",
       "      <td>[centrality, vertex, graph, index, v, network,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fulldata_SocialLearningL2.txt</td>\n",
       "      <td>Social Learning in Networks       ...</td>\n",
       "      <td>Social Learning in Networks       ...</td>\n",
       "      <td>social learning network module network science...</td>\n",
       "      <td>[social, learning, network, module, network, s...</td>\n",
       "      <td>[belief, learning, agent, network, control, bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fulldata_NCMch10.txt</td>\n",
       "      <td>CHAPTER 10  Matching Markets  We have now seen...</td>\n",
       "      <td>CHAPTER 10  Matching Markets  We have now seen...</td>\n",
       "      <td>chapter matching market seen number way thinki...</td>\n",
       "      <td>[chapter, matching, market, seen, number, way,...</td>\n",
       "      <td>[price, graph, buyer, matching, valuation, sel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>fulldata_NCMch14.txt</td>\n",
       "      <td>CHAPTER 14  Link Analysis and Web Search  14.1...</td>\n",
       "      <td>CHAPTER 14  Link Analysis and Web Search  14.1...</td>\n",
       "      <td>chapter link analysis web search searching web...</td>\n",
       "      <td>[chapter, link, analysis, web, search, searchi...</td>\n",
       "      <td>[page, search, pagerank, web, authority, link,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>fulldata_LNch12.txt</td>\n",
       "      <td>12 Network Comparison  Michael Baur and Marc B...</td>\n",
       "      <td>12 Network Comparison  Michael Baur and Marc B...</td>\n",
       "      <td>network comparison michael baur marc benkert f...</td>\n",
       "      <td>[network, comparison, michael, baur, marc, ben...</td>\n",
       "      <td>[graph, g, vertex, v, algorithm, distance, f, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>fulldata_LNch1.txt</td>\n",
       "      <td>1 Introduction  Ulrik Brandes and Thomas Erleb...</td>\n",
       "      <td>1 Introduction  Ulrik Brandes and Thomas Erleb...</td>\n",
       "      <td>introduction ulrik brandes thomas erlebach man...</td>\n",
       "      <td>[introduction, ulrik, brandes, thomas, erlebac...</td>\n",
       "      <td>[network, analysis, www, document, chapter, bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>fulldata_NetworkCENTRALITYL2.txt</td>\n",
       "      <td>Shapley Value Recap     Cooperating Agents: A...</td>\n",
       "      <td>Shapley Value Recap     Cooperating Agents: A...</td>\n",
       "      <td>shapley value recap cooperating agent agent wi...</td>\n",
       "      <td>[shapley, value, recap, cooperating, agent, ag...</td>\n",
       "      <td>[value, node, coalition, network, j, shapley, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>fulldata_NCMch7.txt</td>\n",
       "      <td>CHAPTER 7  Evolutionary Game Theory  In Chapte...</td>\n",
       "      <td>CHAPTER 7  Evolutionary Game Theory  In Chapte...</td>\n",
       "      <td>chapter evolutionary game theory chapter devel...</td>\n",
       "      <td>[chapter, evolutionary, game, theory, chapter,...</td>\n",
       "      <td>[strategy, game, population, payoff, player, f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         resource_id  \\\n",
       "0                 fulldata_LNch7.txt   \n",
       "1              fulldata_Mandate2.txt   \n",
       "2                 fulldata_LNch3.txt   \n",
       "3      fulldata_SocialLearningL2.txt   \n",
       "4               fulldata_NCMch10.txt   \n",
       "..                               ...   \n",
       "62              fulldata_NCMch14.txt   \n",
       "63               fulldata_LNch12.txt   \n",
       "64                fulldata_LNch1.txt   \n",
       "65  fulldata_NetworkCENTRALITYL2.txt   \n",
       "66               fulldata_NCMch7.txt   \n",
       "\n",
       "                                          description  \\\n",
       "0   7 Connectivity  Frank Kammer and Hanjo T¨aubig...   \n",
       "1   Network Science   for the Web  Mandate - 2: St...   \n",
       "2   3 Centrality Indices Dirk Kosch¨utzki,∗ Kathar...   \n",
       "3               Social Learning in Networks       ...   \n",
       "4   CHAPTER 10  Matching Markets  We have now seen...   \n",
       "..                                                ...   \n",
       "62  CHAPTER 14  Link Analysis and Web Search  14.1...   \n",
       "63  12 Network Comparison  Michael Baur and Marc B...   \n",
       "64  1 Introduction  Ulrik Brandes and Thomas Erleb...   \n",
       "65  Shapley Value Recap     Cooperating Agents: A...   \n",
       "66  CHAPTER 7  Evolutionary Game Theory  In Chapte...   \n",
       "\n",
       "                                            full_text  \\\n",
       "0   7 Connectivity  Frank Kammer and Hanjo T¨aubig...   \n",
       "1   Network Science   for the Web  Mandate - 2: St...   \n",
       "2   3 Centrality Indices Dirk Kosch¨utzki,∗ Kathar...   \n",
       "3               Social Learning in Networks       ...   \n",
       "4   CHAPTER 10  Matching Markets  We have now seen...   \n",
       "..                                                ...   \n",
       "62  CHAPTER 14  Link Analysis and Web Search  14.1...   \n",
       "63  12 Network Comparison  Michael Baur and Marc B...   \n",
       "64  1 Introduction  Ulrik Brandes and Thomas Erleb...   \n",
       "65  Shapley Value Recap     Cooperating Agents: A...   \n",
       "66  CHAPTER 7  Evolutionary Game Theory  In Chapte...   \n",
       "\n",
       "                                           clean_text  \\\n",
       "0   connectivity frank kammer hanjo aubig chapter ...   \n",
       "1   network science web mandate structural analysi...   \n",
       "2   centrality index dirk kosch utzki katharina an...   \n",
       "3   social learning network module network science...   \n",
       "4   chapter matching market seen number way thinki...   \n",
       "..                                                ...   \n",
       "62  chapter link analysis web search searching web...   \n",
       "63  network comparison michael baur marc benkert f...   \n",
       "64  introduction ulrik brandes thomas erlebach man...   \n",
       "65  shapley value recap cooperating agent agent wi...   \n",
       "66  chapter evolutionary game theory chapter devel...   \n",
       "\n",
       "                                               tokens  \\\n",
       "0   [connectivity, frank, kammer, hanjo, aubig, ch...   \n",
       "1   [network, science, web, mandate, structural, a...   \n",
       "2   [centrality, index, dirk, kosch, utzki, kathar...   \n",
       "3   [social, learning, network, module, network, s...   \n",
       "4   [chapter, matching, market, seen, number, way,...   \n",
       "..                                                ...   \n",
       "62  [chapter, link, analysis, web, search, searchi...   \n",
       "63  [network, comparison, michael, baur, marc, ben...   \n",
       "64  [introduction, ulrik, brandes, thomas, erlebac...   \n",
       "65  [shapley, value, recap, cooperating, agent, ag...   \n",
       "66  [chapter, evolutionary, game, theory, chapter,...   \n",
       "\n",
       "                                             keywords  \n",
       "0   [graph, vertex, g, edge, algorithm, v, connect...  \n",
       "1   [graph, node, centrality, game, network, v, me...  \n",
       "2   [centrality, vertex, graph, index, v, network,...  \n",
       "3   [belief, learning, agent, network, control, bi...  \n",
       "4   [price, graph, buyer, matching, valuation, sel...  \n",
       "..                                                ...  \n",
       "62  [page, search, pagerank, web, authority, link,...  \n",
       "63  [graph, g, vertex, v, algorithm, distance, f, ...  \n",
       "64  [network, analysis, www, document, chapter, bo...  \n",
       "65  [value, node, coalition, network, j, shapley, ...  \n",
       "66  [strategy, game, population, payoff, player, f...  \n",
       "\n",
       "[67 rows x 6 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics=[]\n",
    "for i in range(len(corpus)):\n",
    "    l = corpus['tokens'][i]\n",
    "    k = corpus['keywords'][i]\n",
    "    dic = {}\n",
    "    for j in l:\n",
    "        if j not in k:\n",
    "            continue\n",
    "        if j in dic.keys():\n",
    "            dic[j]+=1\n",
    "        else:\n",
    "            dic[j]=1\n",
    "    sort = sorted(dic, key=dic.get)\n",
    "    sort.reverse()\n",
    "    l = []\n",
    "    for j in range(10):\n",
    "        l.append(sort[j])\n",
    "    topics.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = pd.DataFrame(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics['resource_id']= corpus['resource_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = topics[['resource_id',0,1,2,3,4,5,6,7,8,9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resource_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fulldata_LNch7.txt</td>\n",
       "      <td>vertex</td>\n",
       "      <td>graph</td>\n",
       "      <td>edge</td>\n",
       "      <td>minimum</td>\n",
       "      <td>cut</td>\n",
       "      <td>set</td>\n",
       "      <td>algorithm</td>\n",
       "      <td>tree</td>\n",
       "      <td>component</td>\n",
       "      <td>connectivity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fulldata_Mandate2.txt</td>\n",
       "      <td>graph</td>\n",
       "      <td>node</td>\n",
       "      <td>centrality</td>\n",
       "      <td>measure</td>\n",
       "      <td>element</td>\n",
       "      <td>network</td>\n",
       "      <td>game</td>\n",
       "      <td>utility</td>\n",
       "      <td>closeness</td>\n",
       "      <td>vitality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fulldata_LNch3.txt</td>\n",
       "      <td>centrality</td>\n",
       "      <td>vertex</td>\n",
       "      <td>graph</td>\n",
       "      <td>index</td>\n",
       "      <td>path</td>\n",
       "      <td>edge</td>\n",
       "      <td>network</td>\n",
       "      <td>value</td>\n",
       "      <td>section</td>\n",
       "      <td>measure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fulldata_SocialLearningL2.txt</td>\n",
       "      <td>belief</td>\n",
       "      <td>learning</td>\n",
       "      <td>agent</td>\n",
       "      <td>social</td>\n",
       "      <td>network</td>\n",
       "      <td>control</td>\n",
       "      <td>signal</td>\n",
       "      <td>model</td>\n",
       "      <td>influence</td>\n",
       "      <td>bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fulldata_NCMch10.txt</td>\n",
       "      <td>matching</td>\n",
       "      <td>price</td>\n",
       "      <td>buyer</td>\n",
       "      <td>set</td>\n",
       "      <td>seller</td>\n",
       "      <td>valuation</td>\n",
       "      <td>house</td>\n",
       "      <td>node</td>\n",
       "      <td>graph</td>\n",
       "      <td>auction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>fulldata_NCMch14.txt</td>\n",
       "      <td>pagerank</td>\n",
       "      <td>page</td>\n",
       "      <td>node</td>\n",
       "      <td>link</td>\n",
       "      <td>value</td>\n",
       "      <td>authority</td>\n",
       "      <td>update</td>\n",
       "      <td>web</td>\n",
       "      <td>hub</td>\n",
       "      <td>search</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>fulldata_LNch12.txt</td>\n",
       "      <td>graph</td>\n",
       "      <td>vertex</td>\n",
       "      <td>algorithm</td>\n",
       "      <td>let</td>\n",
       "      <td>isomorphism</td>\n",
       "      <td>partition</td>\n",
       "      <td>distance</td>\n",
       "      <td>order</td>\n",
       "      <td>cell</td>\n",
       "      <td>number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>fulldata_LNch1.txt</td>\n",
       "      <td>network</td>\n",
       "      <td>analysis</td>\n",
       "      <td>document</td>\n",
       "      <td>chapter</td>\n",
       "      <td>www</td>\n",
       "      <td>group</td>\n",
       "      <td>com</td>\n",
       "      <td>web</td>\n",
       "      <td>graph</td>\n",
       "      <td>actor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>fulldata_NetworkCENTRALITYL2.txt</td>\n",
       "      <td>node</td>\n",
       "      <td>value</td>\n",
       "      <td>fsv</td>\n",
       "      <td>network</td>\n",
       "      <td>coalition</td>\n",
       "      <td>link</td>\n",
       "      <td>shapley</td>\n",
       "      <td>fringe</td>\n",
       "      <td>degree</td>\n",
       "      <td>agent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>fulldata_NCMch7.txt</td>\n",
       "      <td>strategy</td>\n",
       "      <td>game</td>\n",
       "      <td>payoff</td>\n",
       "      <td>population</td>\n",
       "      <td>beetle</td>\n",
       "      <td>player</td>\n",
       "      <td>evolutionary</td>\n",
       "      <td>fitness</td>\n",
       "      <td>equilibrium</td>\n",
       "      <td>nash</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         resource_id           0         1           2  \\\n",
       "0                 fulldata_LNch7.txt      vertex     graph        edge   \n",
       "1              fulldata_Mandate2.txt       graph      node  centrality   \n",
       "2                 fulldata_LNch3.txt  centrality    vertex       graph   \n",
       "3      fulldata_SocialLearningL2.txt      belief  learning       agent   \n",
       "4               fulldata_NCMch10.txt    matching     price       buyer   \n",
       "..                               ...         ...       ...         ...   \n",
       "62              fulldata_NCMch14.txt    pagerank      page        node   \n",
       "63               fulldata_LNch12.txt       graph    vertex   algorithm   \n",
       "64                fulldata_LNch1.txt     network  analysis    document   \n",
       "65  fulldata_NetworkCENTRALITYL2.txt        node     value         fsv   \n",
       "66               fulldata_NCMch7.txt    strategy      game      payoff   \n",
       "\n",
       "             3            4          5             6        7            8  \\\n",
       "0      minimum          cut        set     algorithm     tree    component   \n",
       "1      measure      element    network          game  utility    closeness   \n",
       "2        index         path       edge       network    value      section   \n",
       "3       social      network    control        signal    model    influence   \n",
       "4          set       seller  valuation         house     node        graph   \n",
       "..         ...          ...        ...           ...      ...          ...   \n",
       "62        link        value  authority        update      web          hub   \n",
       "63         let  isomorphism  partition      distance    order         cell   \n",
       "64     chapter          www      group           com      web        graph   \n",
       "65     network    coalition       link       shapley   fringe       degree   \n",
       "66  population       beetle     player  evolutionary  fitness  equilibrium   \n",
       "\n",
       "               9  \n",
       "0   connectivity  \n",
       "1       vitality  \n",
       "2        measure  \n",
       "3           bias  \n",
       "4        auction  \n",
       "..           ...  \n",
       "62        search  \n",
       "63        number  \n",
       "64         actor  \n",
       "65         agent  \n",
       "66          nash  \n",
       "\n",
       "[67 rows x 11 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics.to_csv(\"top_10_textrank.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
