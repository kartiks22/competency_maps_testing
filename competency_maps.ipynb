{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "import contractions\n",
    "import google_list\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '/home/werewolf97/imtech/pro/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = Path(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/werewolf97/imtech/pro/data')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_path = Path.joinpath(input_path.parent, \"converted_files\")\n",
    "if not os.path.exists(converted_path):\n",
    "    os.mkdir(converted_path)\n",
    "#print(type(self.input_path.as_posix()))\n",
    "files = input_path.rglob(f\"*.pdf\")\n",
    "#print(\"Files found: {0}\".format(files))\n",
    "exts = [\".pdf\", \".txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in input_path.rglob('*'):\n",
    "#     path = dirc+file\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read().replace('\\n', ' ')\n",
    "    if content is not None:\n",
    "        data = [f'{file.parent.name}_{file.name}', content]\n",
    "        text_data.append(data)\n",
    "text_corpus = pd.DataFrame(text_data, columns=['resource_id', 'description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = text_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['full_text'] = \"\"\n",
    "corpus['full_text'] = corpus['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_html_tags(text):\n",
    "#     \"\"\"Strips the HTML Tags from the text\"\"\"\n",
    "    try:\n",
    "        soup = BeautifulSoup(text, \"html.parser\")\n",
    "        stripped_text = soup.get_text()\n",
    "    except:\n",
    "        stripped_text = text\n",
    "    return stripped_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accented_chars(text):\n",
    "#         \"\"\"Remove Non UTF-8 Characters from text\"\"\"\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contractions(text, contraction_mapping=contractions.CONTRACTION_MAP):\n",
    "#         \"\"\"Replace contractions in string of text\"\"\"\n",
    "        contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())),\n",
    "                                          flags=re.IGNORECASE | re.DOTALL)\n",
    "\n",
    "        def expand_match(contraction):\n",
    "            match = contraction.group(0)\n",
    "            first_char = match[0]\n",
    "            expanded_contraction = contraction_mapping.get(match) \\\n",
    "                if contraction_mapping.get(match) \\\n",
    "                else contraction_mapping.get(match.lower())\n",
    "            expanded_contraction = first_char + expanded_contraction[1:]\n",
    "            return expanded_contraction\n",
    "\n",
    "        try:\n",
    "            expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "            expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "        except:\n",
    "            expanded_text = text\n",
    "        return expanded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "#         \"\"\"Use the ToktokTokenizer to obtain tokens from the text\"\"\"\n",
    "    tokenizer = nltk.tokenize.toktok.ToktokTokenizer()\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "#         \"\"\"Lemmatize the text using the WordNetLemmatizer\"\"\"\n",
    "    tokenizer = nltk.tokenize.toktok.ToktokTokenizer()\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in tokens])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(text, remove_digits):\n",
    "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords( text):\n",
    "#         \"\"\"Remove Stopwords defined in the stopwords corpus\"\"\"\n",
    "    tokenizer = nltk.tokenize.toktok.ToktokTokenizer()\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    stopword_list = nltk.corpus.stopwords.words('english')\n",
    "    stopword_list.remove('no')\n",
    "    stopword_list.remove('not')\n",
    "    filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    tokens = filtered_tokens\n",
    "    stopword_list = google_list.stopwords\n",
    "    filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_corpus(corpus):\n",
    "    normalized_corpus = []\n",
    "    counter = 0\n",
    "    for i in range(len(corpus)):\n",
    "        doc = corpus['description'][i]\n",
    "        counter += 1\n",
    "        doc = strip_html_tags(doc)\n",
    "        doc = remove_accented_chars(doc)\n",
    "        doc = expand_contractions(doc)\n",
    "        doc = doc.lower()\n",
    "        doc = re.sub(r'[\\r|\\n|\\r\\n]+', ' ', doc)\n",
    "        doc = lemmatize_text(doc)\n",
    "        special_char_pattern = re.compile(r'([{.(-)!}])')\n",
    "        doc = special_char_pattern.sub(\" \\\\1 \", doc)\n",
    "        doc = remove_special_characters(doc, remove_digits= True)\n",
    "        doc = re.sub(' +', ' ', doc)\n",
    "        doc = remove_stopwords(doc)\n",
    "        normalized_corpus.append(doc)\n",
    "    return normalized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['clean_text'] = normalize_corpus(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(corpus):\n",
    "#         \"\"\"Obtain Tokens for each document in the corpus\"\"\"\n",
    "#     tokenizer = nltk.tokenize.toktok.ToktokTokenizer()\n",
    "    tokenized_doc = []\n",
    "    for doc in corpus:\n",
    "        tokens = tokenize(doc)\n",
    "        filtered_tokens = [w for w in tokens if len(w) > 2]\n",
    "        tokenized_doc.append(filtered_tokens)\n",
    "    return tokenized_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['tokens'] = get_tokens(corpus['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = corpus['tokens'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resource_id</th>\n",
       "      <th>description</th>\n",
       "      <th>full_text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data_LNch7.txt</td>\n",
       "      <td>7 Connectivity  Frank Kammer and Hanjo T¨aubig...</td>\n",
       "      <td>7 Connectivity  Frank Kammer and Hanjo T¨aubig...</td>\n",
       "      <td>kammer hanjo aubig tices edgedisjoint vertices...</td>\n",
       "      <td>[kammer, hanjo, aubig, tices, edgedisjoint, ve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data_Mandate2.txt</td>\n",
       "      <td>Network Science   for the Web  Mandate - 2: St...</td>\n",
       "      <td>Network Science   for the Web  Mandate - 2: St...</td>\n",
       "      <td>centrality simultaneous latent semantics found...</td>\n",
       "      <td>[centrality, simultaneous, latent, semantics, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data_LNch3.txt</td>\n",
       "      <td>3 Centrality Indices Dirk Kosch¨utzki,∗ Kathar...</td>\n",
       "      <td>3 Centrality Indices Dirk Kosch¨utzki,∗ Kathar...</td>\n",
       "      <td>centrality dirk kosch utzki katharina lehmann ...</td>\n",
       "      <td>[centrality, dirk, kosch, utzki, katharina, le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data_SocialLearningL2.txt</td>\n",
       "      <td>Social Learning in Networks       ...</td>\n",
       "      <td>Social Learning in Networks       ...</td>\n",
       "      <td>nonbayesian hoc specie interacting andor obser...</td>\n",
       "      <td>[nonbayesian, hoc, specie, interacting, andor,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data_NCMch10.txt</td>\n",
       "      <td>CHAPTER 10  Matching Markets  We have now seen...</td>\n",
       "      <td>CHAPTER 10  Matching Markets  We have now seen...</td>\n",
       "      <td>brae paradox networkstructured implicit encode...</td>\n",
       "      <td>[brae, paradox, networkstructured, implicit, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>data_NCMch14.txt</td>\n",
       "      <td>CHAPTER 14  Link Analysis and Web Search  14.1...</td>\n",
       "      <td>CHAPTER 14  Link Analysis and Web Search  14.1...</td>\n",
       "      <td>edu intrinsic [ ] reponse inexpressive suffers...</td>\n",
       "      <td>[edu, intrinsic, reponse, inexpressive, suffer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>data_LNch12.txt</td>\n",
       "      <td>12 Network Comparison  Michael Baur and Marc B...</td>\n",
       "      <td>12 Network Comparison  Michael Baur and Marc B...</td>\n",
       "      <td>baur benkert formalize equivalence undirected ...</td>\n",
       "      <td>[baur, benkert, formalize, equivalence, undire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>data_LNch1.txt</td>\n",
       "      <td>1 Introduction  Ulrik Brandes and Thomas Erleb...</td>\n",
       "      <td>1 Introduction  Ulrik Brandes and Thomas Erleb...</td>\n",
       "      <td>ulrik brandes erlebach misleading overloaded d...</td>\n",
       "      <td>[ulrik, brandes, erlebach, misleading, overloa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>data_NetworkCENTRALITYL2.txt</td>\n",
       "      <td>Shapley Value Recap     Cooperating Agents: A...</td>\n",
       "      <td>Shapley Value Recap     Cooperating Agents: A...</td>\n",
       "      <td>shapley recap cooperating shapley distributes ...</td>\n",
       "      <td>[shapley, recap, cooperating, shapley, distrib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>data_NCMch7.txt</td>\n",
       "      <td>CHAPTER 7  Evolutionary Game Theory  In Chapte...</td>\n",
       "      <td>CHAPTER 7  Evolutionary Game Theory  In Chapte...</td>\n",
       "      <td>evolutionary payoff evolutionary overtly gamet...</td>\n",
       "      <td>[evolutionary, payoff, evolutionary, overtly, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     resource_id  \\\n",
       "0                 data_LNch7.txt   \n",
       "1              data_Mandate2.txt   \n",
       "2                 data_LNch3.txt   \n",
       "3      data_SocialLearningL2.txt   \n",
       "4               data_NCMch10.txt   \n",
       "..                           ...   \n",
       "62              data_NCMch14.txt   \n",
       "63               data_LNch12.txt   \n",
       "64                data_LNch1.txt   \n",
       "65  data_NetworkCENTRALITYL2.txt   \n",
       "66               data_NCMch7.txt   \n",
       "\n",
       "                                          description  \\\n",
       "0   7 Connectivity  Frank Kammer and Hanjo T¨aubig...   \n",
       "1   Network Science   for the Web  Mandate - 2: St...   \n",
       "2   3 Centrality Indices Dirk Kosch¨utzki,∗ Kathar...   \n",
       "3               Social Learning in Networks       ...   \n",
       "4   CHAPTER 10  Matching Markets  We have now seen...   \n",
       "..                                                ...   \n",
       "62  CHAPTER 14  Link Analysis and Web Search  14.1...   \n",
       "63  12 Network Comparison  Michael Baur and Marc B...   \n",
       "64  1 Introduction  Ulrik Brandes and Thomas Erleb...   \n",
       "65  Shapley Value Recap     Cooperating Agents: A...   \n",
       "66  CHAPTER 7  Evolutionary Game Theory  In Chapte...   \n",
       "\n",
       "                                            full_text  \\\n",
       "0   7 Connectivity  Frank Kammer and Hanjo T¨aubig...   \n",
       "1   Network Science   for the Web  Mandate - 2: St...   \n",
       "2   3 Centrality Indices Dirk Kosch¨utzki,∗ Kathar...   \n",
       "3               Social Learning in Networks       ...   \n",
       "4   CHAPTER 10  Matching Markets  We have now seen...   \n",
       "..                                                ...   \n",
       "62  CHAPTER 14  Link Analysis and Web Search  14.1...   \n",
       "63  12 Network Comparison  Michael Baur and Marc B...   \n",
       "64  1 Introduction  Ulrik Brandes and Thomas Erleb...   \n",
       "65  Shapley Value Recap     Cooperating Agents: A...   \n",
       "66  CHAPTER 7  Evolutionary Game Theory  In Chapte...   \n",
       "\n",
       "                                           clean_text  \\\n",
       "0   kammer hanjo aubig tices edgedisjoint vertices...   \n",
       "1   centrality simultaneous latent semantics found...   \n",
       "2   centrality dirk kosch utzki katharina lehmann ...   \n",
       "3   nonbayesian hoc specie interacting andor obser...   \n",
       "4   brae paradox networkstructured implicit encode...   \n",
       "..                                                ...   \n",
       "62  edu intrinsic [ ] reponse inexpressive suffers...   \n",
       "63  baur benkert formalize equivalence undirected ...   \n",
       "64  ulrik brandes erlebach misleading overloaded d...   \n",
       "65  shapley recap cooperating shapley distributes ...   \n",
       "66  evolutionary payoff evolutionary overtly gamet...   \n",
       "\n",
       "                                               tokens  \n",
       "0   [kammer, hanjo, aubig, tices, edgedisjoint, ve...  \n",
       "1   [centrality, simultaneous, latent, semantics, ...  \n",
       "2   [centrality, dirk, kosch, utzki, katharina, le...  \n",
       "3   [nonbayesian, hoc, specie, interacting, andor,...  \n",
       "4   [brae, paradox, networkstructured, implicit, e...  \n",
       "..                                                ...  \n",
       "62  [edu, intrinsic, reponse, inexpressive, suffer...  \n",
       "63  [baur, benkert, formalize, equivalence, undire...  \n",
       "64  [ulrik, brandes, erlebach, misleading, overloa...  \n",
       "65  [shapley, recap, cooperating, shapley, distrib...  \n",
       "66  [evolutionary, payoff, evolutionary, overtly, ...  \n",
       "\n",
       "[67 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "for i in l:\n",
    "    if i in dic.keys():\n",
    "        dic[i]+=1\n",
    "    else:\n",
    "        dic[i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort = sorted(dic, key=dic.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kammer': 18,\n",
       " 'hanjo': 1,\n",
       " 'aubig': 18,\n",
       " 'tices': 4,\n",
       " 'edgedisjoint': 8,\n",
       " 'vertices': 11,\n",
       " 'kvertex': 1,\n",
       " 'kedge': 1,\n",
       " 'maximal': 9,\n",
       " 'kconnected': 3,\n",
       " 'summarize': 1,\n",
       " 'denote': 9,\n",
       " 'vertexconnectivity': 11,\n",
       " 'cannot': 4,\n",
       " 'undirected': 26,\n",
       " 'symmetric': 2,\n",
       " 'parenthesis': 1,\n",
       " 'articulation': 2,\n",
       " 'cutedge': 2,\n",
       " 'isthmus': 1,\n",
       " 'ponent': 2,\n",
       " 'biconnected': 25,\n",
       " 'nonseparable': 2,\n",
       " 'compo': 2,\n",
       " 'nent': 1,\n",
       " 'cutvertex': 10,\n",
       " 'ilarly': 1,\n",
       " 'subgraph': 11,\n",
       " 'chap': 1,\n",
       " 'ter': 1,\n",
       " 'disconnect': 2,\n",
       " 'brandes': 1,\n",
       " 'erlebach': 1,\n",
       " 'lncs': 1,\n",
       " 'cid': 272,\n",
       " 'springerverlag': 1,\n",
       " 'heidelberg': 1,\n",
       " 'vertexdisjoint': 5,\n",
       " 'vertexcutset': 1,\n",
       " 'edgecutset': 1,\n",
       " 'vertexedgedisjoint': 1,\n",
       " 'vertexedgecutsets': 1,\n",
       " 'cutedges': 1,\n",
       " 'subgraphs': 4,\n",
       " 'blockgraph': 2,\n",
       " 'correspond': 1,\n",
       " 'cutpointgraph': 2,\n",
       " 'cutvertices': 5,\n",
       " 'reside': 2,\n",
       " 'blockcutpointgraph': 1,\n",
       " 'bipartite': 1,\n",
       " 'blockvertex': 1,\n",
       " 'blockcutpoint': 1,\n",
       " 'kvertexconnected': 1,\n",
       " 'edgeconnected': 1,\n",
       " 'kvertexcomponents': 2,\n",
       " 'kedgecomponents': 3,\n",
       " 'kedgecomponent': 1,\n",
       " 'nontrivial': 4,\n",
       " 'bounded': 6,\n",
       " 'separator': 8,\n",
       " 'graphtheoretic': 1,\n",
       " 'lished': 1,\n",
       " 'menger': 2,\n",
       " 'subset': 10,\n",
       " 'cardinality': 4,\n",
       " 'intersecting': 1,\n",
       " 'nchain': 1,\n",
       " 'narc': 1,\n",
       " 'corollary': 5,\n",
       " 'mengers': 8,\n",
       " 'undi': 2,\n",
       " 'rected': 2,\n",
       " 'stpaths': 2,\n",
       " 'stvertex': 1,\n",
       " 'edgecuts': 1,\n",
       " 'stedgeseparator': 1,\n",
       " 'explicitely': 1,\n",
       " 'fulkerson': 5,\n",
       " 'dantzig': 2,\n",
       " 'elia': 1,\n",
       " 'feinstein': 1,\n",
       " 'maxflow': 11,\n",
       " 'mincut': 2,\n",
       " 'variant': 3,\n",
       " 'hassler': 1,\n",
       " 'whitney': 3,\n",
       " 'deriving': 1,\n",
       " 'precondition': 1,\n",
       " 'sion': 1,\n",
       " 'kedgeconnected': 1,\n",
       " 'schrijver': 1,\n",
       " 'beineke': 3,\n",
       " 'harary': 3,\n",
       " 'edgeconnectivity': 12,\n",
       " 'vertexedge': 4,\n",
       " 'mutually': 1,\n",
       " 'nonintersecting': 1,\n",
       " 'chartrand': 1,\n",
       " 'kvertexedgecomponents': 1,\n",
       " 'generalized': 2,\n",
       " 'kodama': 1,\n",
       " 'overlap': 1,\n",
       " 'matula': 6,\n",
       " 'overlapping': 1,\n",
       " 'decom': 1,\n",
       " 'edgecut': 4,\n",
       " 'disconnected': 3,\n",
       " 'trivial': 5,\n",
       " 'contradict': 1,\n",
       " 'minit': 1,\n",
       " 'prof': 1,\n",
       " 'kvertexedgeconnectivity': 2,\n",
       " 'converse': 2,\n",
       " 'mader': 1,\n",
       " 'spanning': 13,\n",
       " 'rooted': 3,\n",
       " 'rbranchings': 2,\n",
       " 'edmonds': 2,\n",
       " 'branching': 2,\n",
       " 'multigraph': 6,\n",
       " 'pairwise': 5,\n",
       " 'denotes': 3,\n",
       " 'lov': 2,\n",
       " 'asz': 2,\n",
       " 'interrelation': 1,\n",
       " 'outdegree': 3,\n",
       " 'kotzigs': 2,\n",
       " 'jecture': 1,\n",
       " 'pseudosymmetric': 1,\n",
       " 'indegree': 2,\n",
       " 'endpoint': 1,\n",
       " 'disjoint': 9,\n",
       " 'denoted': 4,\n",
       " 'unweighted': 3,\n",
       " 'induces': 2,\n",
       " 'computes': 8,\n",
       " 'dinitz': 3,\n",
       " 'cactus': 18,\n",
       " 'karzanov': 2,\n",
       " 'timofeev': 1,\n",
       " 'nphard': 3,\n",
       " 'generalization': 2,\n",
       " 'assigning': 1,\n",
       " 'rfmax': 2,\n",
       " 'residual': 1,\n",
       " 'fmax': 2,\n",
       " 'stflow': 1,\n",
       " 'saturates': 1,\n",
       " 'stcuts': 1,\n",
       " 'stcut': 4,\n",
       " 'iff': 1,\n",
       " 'allpairs': 1,\n",
       " 'gomory': 1,\n",
       " 'pacity': 1,\n",
       " 'resid': 1,\n",
       " 'ual': 1,\n",
       " 'yond': 1,\n",
       " 'grf': 1,\n",
       " 'urf': 2,\n",
       " 'stpath': 1,\n",
       " 'gomoryhu': 1,\n",
       " 'gusfield': 1,\n",
       " 'contraction': 2,\n",
       " 'cutset': 1,\n",
       " 'stoer': 4,\n",
       " 'polynomial': 1,\n",
       " 'discus': 2,\n",
       " 'wellknown': 1,\n",
       " 'omitted': 1,\n",
       " 'lemma': 46,\n",
       " 's\\\\t': 1,\n",
       " 'contradiction': 8,\n",
       " 'inequality': 3,\n",
       " 'imum': 2,\n",
       " 'summing': 2,\n",
       " 'diagonal': 1,\n",
       " 'separating': 3,\n",
       " 'proportional': 2,\n",
       " 'midpoint': 1,\n",
       " 'refinement': 2,\n",
       " 'iavi': 2,\n",
       " 'tained': 1,\n",
       " 'fore': 1,\n",
       " 'transformed': 1,\n",
       " 'interchange': 2,\n",
       " 'concludes': 3,\n",
       " 'terminates': 1,\n",
       " 'partitioning': 1,\n",
       " 'splitting': 2,\n",
       " 'mum': 2,\n",
       " 'recursive': 2,\n",
       " 'achieves': 1,\n",
       " 'partitions': 1,\n",
       " 'laminar': 4,\n",
       " 'versa': 1,\n",
       " 'superset': 2,\n",
       " 'subtree': 2,\n",
       " 'mapped': 6,\n",
       " 'corresponds': 4,\n",
       " 'conversely': 2,\n",
       " 'treelike': 1,\n",
       " 'flowbased': 4,\n",
       " 'distinguish': 1,\n",
       " 'kvertexedgeconnected': 1,\n",
       " 'kcomponents': 1,\n",
       " 'edgeconnectivities': 3,\n",
       " 'pacities': 1,\n",
       " 'simplex': 1,\n",
       " 'augmenting': 2,\n",
       " 'labeling': 2,\n",
       " 'karp': 1,\n",
       " 'shortest': 2,\n",
       " 'scaling': 3,\n",
       " 'layered': 2,\n",
       " 'nmu': 2,\n",
       " 'goldberg': 4,\n",
       " 'tarjan': 11,\n",
       " 'pushrelabel': 2,\n",
       " 'preflowpush': 1,\n",
       " 'cherkassky': 1,\n",
       " 'malhotra': 1,\n",
       " 'kumar': 1,\n",
       " 'maheshwari': 1,\n",
       " 'galil': 2,\n",
       " 'naamad': 1,\n",
       " 'shiloach': 1,\n",
       " 'sleater': 1,\n",
       " 'logmn': 1,\n",
       " 'derandomization': 1,\n",
       " 'rao': 5,\n",
       " 'ahuja': 1,\n",
       " 'orlin': 1,\n",
       " 'cheriyan': 2,\n",
       " 'hagerup': 1,\n",
       " 'mehlhorn': 1,\n",
       " 'westbrook': 1,\n",
       " 'nonunit': 1,\n",
       " 'incremental': 2,\n",
       " 'alon': 1,\n",
       " 'maxi': 1,\n",
       " 'dinitzs': 3,\n",
       " 'algo': 5,\n",
       " 'rithm': 3,\n",
       " 'differs': 1,\n",
       " 'logarithmic': 1,\n",
       " 'karger': 1,\n",
       " 'levine': 1,\n",
       " 'esfahanian': 8,\n",
       " 'hakimi': 8,\n",
       " 'henzinger': 2,\n",
       " 'gabow': 3,\n",
       " 'kleitman': 1,\n",
       " 'kvc': 1,\n",
       " 'knm': 2,\n",
       " 'subroutine': 5,\n",
       " 'putes': 1,\n",
       " 'derive': 1,\n",
       " 'correctness': 1,\n",
       " 'emanates': 1,\n",
       " 'resp': 2,\n",
       " 'fixing': 1,\n",
       " 'firstly': 1,\n",
       " 'vertexseparators': 1,\n",
       " 'vertexcut': 2,\n",
       " 'vertexcuts': 1,\n",
       " 'tition': 1,\n",
       " 'maximumflow': 1,\n",
       " 'solves': 1,\n",
       " 'antiparallel': 1,\n",
       " 'foreach': 1,\n",
       " 'nonneighbor': 1,\n",
       " 'aforementioned': 1,\n",
       " 'kec': 1,\n",
       " 'nonleaf': 2,\n",
       " 'selects': 1,\n",
       " 'nonleaves': 1,\n",
       " 'quire': 1,\n",
       " 'dominating': 6,\n",
       " 'puted': 1,\n",
       " 'calculating': 1,\n",
       " 'nonflowbased': 2,\n",
       " 'edgeweighted': 1,\n",
       " 'surprisingly': 1,\n",
       " 'rithms': 2,\n",
       " 'prims': 1,\n",
       " 'dijkstras': 1,\n",
       " 'equiva': 1,\n",
       " 'lent': 1,\n",
       " 'cmin': 6,\n",
       " 'tightly': 1,\n",
       " 'initialized': 2,\n",
       " 'repeatedly': 1,\n",
       " 'merged': 1,\n",
       " 'cutofthephase': 4,\n",
       " 'ified': 1,\n",
       " 'predecessor': 2,\n",
       " 'adjacency': 6,\n",
       " 'au\\\\': 1,\n",
       " 'completes': 1,\n",
       " 'cutsof': 1,\n",
       " 'thephase': 1,\n",
       " 'merging': 5,\n",
       " 'randomized': 1,\n",
       " 'becker': 1,\n",
       " 'probabilistic': 2,\n",
       " 'eventarjan': 1,\n",
       " 'sparse': 2,\n",
       " 'linial': 1,\n",
       " 'lovasz': 1,\n",
       " 'wigderson': 1,\n",
       " 'geometric': 1,\n",
       " 'algebraic': 1,\n",
       " 'interpre': 1,\n",
       " 'tation': 2,\n",
       " 'stnumbering': 1,\n",
       " 'degenerate': 1,\n",
       " 'convex': 2,\n",
       " 'embedding': 1,\n",
       " 'specifying': 1,\n",
       " 'bce': 1,\n",
       " 'fgh': 2,\n",
       " 'bcde': 1,\n",
       " 'stoerwagner': 1,\n",
       " 'abdeg': 1,\n",
       " 'perplane': 1,\n",
       " 'montecarlo': 1,\n",
       " 'errs': 1,\n",
       " 'vega': 2,\n",
       " 'reif': 1,\n",
       " 'yielded': 1,\n",
       " 'gorithm': 1,\n",
       " 'multiplication': 1,\n",
       " 'matrices': 1,\n",
       " 'worstcase': 1,\n",
       " 'digraph': 2,\n",
       " 'superlinear': 1,\n",
       " 'hopcroft': 3,\n",
       " 'arises': 1,\n",
       " 'depthfirst': 4,\n",
       " 'traversed': 1,\n",
       " 'preorder': 1,\n",
       " 'numbering': 1,\n",
       " 'num': 2,\n",
       " 'inspect': 1,\n",
       " 'unlabeled': 2,\n",
       " 'backward': 8,\n",
       " 'reachable': 3,\n",
       " 'dfs': 21,\n",
       " 'lowentry': 1,\n",
       " 'descent': 2,\n",
       " 'low[': 8,\n",
       " 'traversal': 6,\n",
       " 'num[': 11,\n",
       " 'discovers': 1,\n",
       " 'successor': 1,\n",
       " 'ancestor': 7,\n",
       " 'dashed': 1,\n",
       " 'analogously': 1,\n",
       " 'restart': 1,\n",
       " 'inspected': 1,\n",
       " 'equivalence': 2,\n",
       " 'partitioned': 1,\n",
       " 'ponents': 1,\n",
       " 'descendant': 8,\n",
       " 'lowlink[': 5,\n",
       " 'arbitrarily': 1,\n",
       " 'numbered': 1,\n",
       " 'scc': 1,\n",
       " 'similarity': 1,\n",
       " 'proach': 1,\n",
       " 'triconnectivity': 2,\n",
       " 'tutte': 1,\n",
       " 'sixty': 1,\n",
       " 'dividing': 3,\n",
       " 'triconnected': 10,\n",
       " 'ramachandran': 1,\n",
       " 'vided': 1,\n",
       " 'decompo': 1,\n",
       " 'sitions': 1,\n",
       " 'hopcrofttarjan': 1,\n",
       " 'gutwenger': 1,\n",
       " 'mutzel': 1,\n",
       " 'faulty': 1,\n",
       " 'spqrtrees': 3,\n",
       " 'recursively': 2,\n",
       " 'polygons': 1,\n",
       " 'planar': 1,\n",
       " 'inclusionmaximal': 1,\n",
       " 'spqrtree': 4,\n",
       " 'spect': 1,\n",
       " 'skeleton': 9,\n",
       " 'stedges': 1,\n",
       " 'qnode': 4,\n",
       " 'pnode': 1,\n",
       " 'snode': 1,\n",
       " 'rigid': 1,\n",
       " 'rnode': 1,\n",
       " 'spqr': 1,\n",
       " 'pnodes': 1,\n",
       " 'cor': 1,\n",
       " 'snodes': 1,\n",
       " 'polygon': 2,\n",
       " 'rnodes': 1,\n",
       " 'corre': 1,\n",
       " 'sketch': 1,\n",
       " 'sponding': 1,\n",
       " 'selfloops': 1,\n",
       " 'preprocessing': 1,\n",
       " 'reordered': 1,\n",
       " 'bucket': 3,\n",
       " 'successively': 1,\n",
       " 'vir': 1,\n",
       " 'tual': 1,\n",
       " 'dfsbased': 1,\n",
       " 'frond': 8,\n",
       " 'relies': 1,\n",
       " 'lowpt': 14,\n",
       " 'traversing': 1,\n",
       " 'adj': 6,\n",
       " 'ascending': 1,\n",
       " 'resides': 1,\n",
       " 'rearrangement': 1,\n",
       " 'sorting': 1,\n",
       " 'confer': 2,\n",
       " 'satisfies': 2,\n",
       " 'omit': 1,\n",
       " 'nents': 1,\n",
       " 'plexity': 1,\n",
       " 'lineartime': 1,\n",
       " 'kosaraju': 1,\n",
       " 'unpublished': 1,\n",
       " 'sharir': 1,\n",
       " 'bfs': 1,\n",
       " 'jiang': 1,\n",
       " 'spacesaving': 1,\n",
       " 'tarjans': 1,\n",
       " 'singlenode': 1,\n",
       " 'nuutila': 1,\n",
       " 'soisalon': 1,\n",
       " 'soininen': 1,\n",
       " 'onepass': 1,\n",
       " 'pute': 2,\n",
       " 'auxiliary': 1,\n",
       " 'oellermann': 4,\n",
       " 'pippert': 1,\n",
       " 'sidered': 1,\n",
       " 'erage': 1,\n",
       " 'dankelmann': 1,\n",
       " 'henning': 1,\n",
       " 'consid': 1,\n",
       " 'ered': 1,\n",
       " 'nectivity': 2,\n",
       " 'dynamical': 1,\n",
       " 'andor': 1,\n",
       " 'deletions': 1,\n",
       " 'inser': 1,\n",
       " 'semidynamic': 1,\n",
       " 'partiallydynamic': 1,\n",
       " 'schnorr': 1,\n",
       " 'mansour': 1,\n",
       " 'schieber': 1,\n",
       " 'compu': 1,\n",
       " 'cohesiveness': 2,\n",
       " 'taining': 1,\n",
       " 'akiyama': 1,\n",
       " 'shredder': 1,\n",
       " 'deletion': 1,\n",
       " 'ith': 1,\n",
       " 'acknowledgments': 1,\n",
       " 'schilder': 1,\n",
       " 'ortrud': 1}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hanjo',\n",
       " 'kvertex',\n",
       " 'kedge',\n",
       " 'summarize',\n",
       " 'parenthesis',\n",
       " 'isthmus',\n",
       " 'nent',\n",
       " 'ilarly',\n",
       " 'chap',\n",
       " 'ter',\n",
       " 'brandes',\n",
       " 'erlebach',\n",
       " 'lncs',\n",
       " 'springerverlag',\n",
       " 'heidelberg',\n",
       " 'vertexcutset',\n",
       " 'edgecutset',\n",
       " 'vertexedgedisjoint',\n",
       " 'vertexedgecutsets',\n",
       " 'cutedges',\n",
       " 'correspond',\n",
       " 'blockcutpointgraph',\n",
       " 'bipartite',\n",
       " 'blockvertex',\n",
       " 'blockcutpoint',\n",
       " 'kvertexconnected',\n",
       " 'edgeconnected',\n",
       " 'kedgecomponent',\n",
       " 'graphtheoretic',\n",
       " 'lished',\n",
       " 'intersecting',\n",
       " 'nchain',\n",
       " 'narc',\n",
       " 'stvertex',\n",
       " 'edgecuts',\n",
       " 'stedgeseparator',\n",
       " 'explicitely',\n",
       " 'elia',\n",
       " 'feinstein',\n",
       " 'hassler',\n",
       " 'deriving',\n",
       " 'precondition',\n",
       " 'sion',\n",
       " 'kedgeconnected',\n",
       " 'schrijver',\n",
       " 'mutually',\n",
       " 'nonintersecting',\n",
       " 'chartrand',\n",
       " 'kvertexedgecomponents',\n",
       " 'kodama',\n",
       " 'overlap',\n",
       " 'overlapping',\n",
       " 'decom',\n",
       " 'contradict',\n",
       " 'minit',\n",
       " 'prof',\n",
       " 'mader',\n",
       " 'interrelation',\n",
       " 'jecture',\n",
       " 'pseudosymmetric',\n",
       " 'endpoint',\n",
       " 'timofeev',\n",
       " 'assigning',\n",
       " 'residual',\n",
       " 'stflow',\n",
       " 'saturates',\n",
       " 'stcuts',\n",
       " 'iff',\n",
       " 'allpairs',\n",
       " 'gomory',\n",
       " 'pacity',\n",
       " 'resid',\n",
       " 'ual',\n",
       " 'yond',\n",
       " 'grf',\n",
       " 'stpath',\n",
       " 'gomoryhu',\n",
       " 'gusfield',\n",
       " 'cutset',\n",
       " 'polynomial',\n",
       " 'wellknown',\n",
       " 'omitted',\n",
       " 's\\\\t',\n",
       " 'diagonal',\n",
       " 'midpoint',\n",
       " 'tained',\n",
       " 'fore',\n",
       " 'transformed',\n",
       " 'terminates',\n",
       " 'partitioning',\n",
       " 'achieves',\n",
       " 'partitions',\n",
       " 'versa',\n",
       " 'treelike',\n",
       " 'distinguish',\n",
       " 'kvertexedgeconnected',\n",
       " 'kcomponents',\n",
       " 'pacities',\n",
       " 'simplex',\n",
       " 'karp',\n",
       " 'preflowpush',\n",
       " 'cherkassky',\n",
       " 'malhotra',\n",
       " 'kumar',\n",
       " 'maheshwari',\n",
       " 'naamad',\n",
       " 'shiloach',\n",
       " 'sleater',\n",
       " 'logmn',\n",
       " 'derandomization',\n",
       " 'ahuja',\n",
       " 'orlin',\n",
       " 'hagerup',\n",
       " 'mehlhorn',\n",
       " 'westbrook',\n",
       " 'nonunit',\n",
       " 'alon',\n",
       " 'maxi',\n",
       " 'differs',\n",
       " 'logarithmic',\n",
       " 'karger',\n",
       " 'levine',\n",
       " 'kleitman',\n",
       " 'kvc',\n",
       " 'putes',\n",
       " 'derive',\n",
       " 'correctness',\n",
       " 'emanates',\n",
       " 'fixing',\n",
       " 'firstly',\n",
       " 'vertexseparators',\n",
       " 'vertexcuts',\n",
       " 'tition',\n",
       " 'maximumflow',\n",
       " 'solves',\n",
       " 'antiparallel',\n",
       " 'foreach',\n",
       " 'nonneighbor',\n",
       " 'aforementioned',\n",
       " 'kec',\n",
       " 'selects',\n",
       " 'nonleaves',\n",
       " 'quire',\n",
       " 'puted',\n",
       " 'calculating',\n",
       " 'edgeweighted',\n",
       " 'surprisingly',\n",
       " 'prims',\n",
       " 'dijkstras',\n",
       " 'equiva',\n",
       " 'lent',\n",
       " 'tightly',\n",
       " 'repeatedly',\n",
       " 'merged',\n",
       " 'ified',\n",
       " 'au\\\\',\n",
       " 'completes',\n",
       " 'cutsof',\n",
       " 'thephase',\n",
       " 'randomized',\n",
       " 'becker',\n",
       " 'eventarjan',\n",
       " 'linial',\n",
       " 'lovasz',\n",
       " 'wigderson',\n",
       " 'geometric',\n",
       " 'algebraic',\n",
       " 'interpre',\n",
       " 'stnumbering',\n",
       " 'degenerate',\n",
       " 'embedding',\n",
       " 'specifying',\n",
       " 'bce',\n",
       " 'bcde',\n",
       " 'stoerwagner',\n",
       " 'abdeg',\n",
       " 'perplane',\n",
       " 'montecarlo',\n",
       " 'errs',\n",
       " 'reif',\n",
       " 'yielded',\n",
       " 'gorithm',\n",
       " 'multiplication',\n",
       " 'matrices',\n",
       " 'worstcase',\n",
       " 'superlinear',\n",
       " 'arises',\n",
       " 'traversed',\n",
       " 'preorder',\n",
       " 'numbering',\n",
       " 'inspect',\n",
       " 'lowentry',\n",
       " 'discovers',\n",
       " 'successor',\n",
       " 'dashed',\n",
       " 'analogously',\n",
       " 'restart',\n",
       " 'inspected',\n",
       " 'partitioned',\n",
       " 'ponents',\n",
       " 'arbitrarily',\n",
       " 'numbered',\n",
       " 'scc',\n",
       " 'similarity',\n",
       " 'proach',\n",
       " 'tutte',\n",
       " 'sixty',\n",
       " 'ramachandran',\n",
       " 'vided',\n",
       " 'decompo',\n",
       " 'sitions',\n",
       " 'hopcrofttarjan',\n",
       " 'gutwenger',\n",
       " 'mutzel',\n",
       " 'faulty',\n",
       " 'polygons',\n",
       " 'planar',\n",
       " 'inclusionmaximal',\n",
       " 'spect',\n",
       " 'stedges',\n",
       " 'pnode',\n",
       " 'snode',\n",
       " 'rigid',\n",
       " 'rnode',\n",
       " 'spqr',\n",
       " 'pnodes',\n",
       " 'cor',\n",
       " 'snodes',\n",
       " 'rnodes',\n",
       " 'corre',\n",
       " 'sketch',\n",
       " 'sponding',\n",
       " 'selfloops',\n",
       " 'preprocessing',\n",
       " 'reordered',\n",
       " 'successively',\n",
       " 'vir',\n",
       " 'tual',\n",
       " 'dfsbased',\n",
       " 'relies',\n",
       " 'traversing',\n",
       " 'ascending',\n",
       " 'resides',\n",
       " 'rearrangement',\n",
       " 'sorting',\n",
       " 'omit',\n",
       " 'nents',\n",
       " 'plexity',\n",
       " 'lineartime',\n",
       " 'kosaraju',\n",
       " 'unpublished',\n",
       " 'sharir',\n",
       " 'bfs',\n",
       " 'jiang',\n",
       " 'spacesaving',\n",
       " 'tarjans',\n",
       " 'singlenode',\n",
       " 'nuutila',\n",
       " 'soisalon',\n",
       " 'soininen',\n",
       " 'onepass',\n",
       " 'auxiliary',\n",
       " 'pippert',\n",
       " 'sidered',\n",
       " 'erage',\n",
       " 'dankelmann',\n",
       " 'henning',\n",
       " 'consid',\n",
       " 'ered',\n",
       " 'dynamical',\n",
       " 'andor',\n",
       " 'deletions',\n",
       " 'inser',\n",
       " 'semidynamic',\n",
       " 'partiallydynamic',\n",
       " 'schnorr',\n",
       " 'mansour',\n",
       " 'schieber',\n",
       " 'compu',\n",
       " 'taining',\n",
       " 'akiyama',\n",
       " 'shredder',\n",
       " 'deletion',\n",
       " 'ith',\n",
       " 'acknowledgments',\n",
       " 'schilder',\n",
       " 'ortrud',\n",
       " 'symmetric',\n",
       " 'articulation',\n",
       " 'cutedge',\n",
       " 'ponent',\n",
       " 'nonseparable',\n",
       " 'compo',\n",
       " 'disconnect',\n",
       " 'blockgraph',\n",
       " 'cutpointgraph',\n",
       " 'reside',\n",
       " 'kvertexcomponents',\n",
       " 'menger',\n",
       " 'undi',\n",
       " 'rected',\n",
       " 'stpaths',\n",
       " 'dantzig',\n",
       " 'mincut',\n",
       " 'generalized',\n",
       " 'kvertexedgeconnectivity',\n",
       " 'converse',\n",
       " 'rbranchings',\n",
       " 'edmonds',\n",
       " 'branching',\n",
       " 'lov',\n",
       " 'asz',\n",
       " 'kotzigs',\n",
       " 'indegree',\n",
       " 'induces',\n",
       " 'karzanov',\n",
       " 'generalization',\n",
       " 'rfmax',\n",
       " 'fmax',\n",
       " 'urf',\n",
       " 'contraction',\n",
       " 'discus',\n",
       " 'imum',\n",
       " 'summing',\n",
       " 'proportional',\n",
       " 'refinement',\n",
       " 'iavi',\n",
       " 'interchange',\n",
       " 'splitting',\n",
       " 'mum',\n",
       " 'recursive',\n",
       " 'superset',\n",
       " 'subtree',\n",
       " 'conversely',\n",
       " 'augmenting',\n",
       " 'labeling',\n",
       " 'shortest',\n",
       " 'layered',\n",
       " 'nmu',\n",
       " 'pushrelabel',\n",
       " 'galil',\n",
       " 'cheriyan',\n",
       " 'incremental',\n",
       " 'henzinger',\n",
       " 'knm',\n",
       " 'resp',\n",
       " 'vertexcut',\n",
       " 'nonleaf',\n",
       " 'nonflowbased',\n",
       " 'rithms',\n",
       " 'initialized',\n",
       " 'predecessor',\n",
       " 'probabilistic',\n",
       " 'sparse',\n",
       " 'tation',\n",
       " 'convex',\n",
       " 'fgh',\n",
       " 'vega',\n",
       " 'digraph',\n",
       " 'num',\n",
       " 'unlabeled',\n",
       " 'descent',\n",
       " 'equivalence',\n",
       " 'triconnectivity',\n",
       " 'recursively',\n",
       " 'polygon',\n",
       " 'confer',\n",
       " 'satisfies',\n",
       " 'pute',\n",
       " 'nectivity',\n",
       " 'cohesiveness',\n",
       " 'kconnected',\n",
       " 'kedgecomponents',\n",
       " 'variant',\n",
       " 'whitney',\n",
       " 'beineke',\n",
       " 'harary',\n",
       " 'disconnected',\n",
       " 'rooted',\n",
       " 'denotes',\n",
       " 'outdegree',\n",
       " 'unweighted',\n",
       " 'dinitz',\n",
       " 'nphard',\n",
       " 'inequality',\n",
       " 'separating',\n",
       " 'concludes',\n",
       " 'edgeconnectivities',\n",
       " 'scaling',\n",
       " 'dinitzs',\n",
       " 'rithm',\n",
       " 'gabow',\n",
       " 'hopcroft',\n",
       " 'reachable',\n",
       " 'dividing',\n",
       " 'spqrtrees',\n",
       " 'bucket',\n",
       " 'tices',\n",
       " 'cannot',\n",
       " 'subgraphs',\n",
       " 'nontrivial',\n",
       " 'cardinality',\n",
       " 'vertexedge',\n",
       " 'edgecut',\n",
       " 'denoted',\n",
       " 'stcut',\n",
       " 'stoer',\n",
       " 'laminar',\n",
       " 'corresponds',\n",
       " 'flowbased',\n",
       " 'goldberg',\n",
       " 'cutofthephase',\n",
       " 'depthfirst',\n",
       " 'spqrtree',\n",
       " 'qnode',\n",
       " 'oellermann',\n",
       " 'vertexdisjoint',\n",
       " 'cutvertices',\n",
       " 'corollary',\n",
       " 'fulkerson',\n",
       " 'trivial',\n",
       " 'pairwise',\n",
       " 'rao',\n",
       " 'algo',\n",
       " 'subroutine',\n",
       " 'merging',\n",
       " 'lowlink[',\n",
       " 'bounded',\n",
       " 'matula',\n",
       " 'multigraph',\n",
       " 'mapped',\n",
       " 'dominating',\n",
       " 'cmin',\n",
       " 'adjacency',\n",
       " 'traversal',\n",
       " 'adj',\n",
       " 'ancestor',\n",
       " 'edgedisjoint',\n",
       " 'separator',\n",
       " 'mengers',\n",
       " 'computes',\n",
       " 'contradiction',\n",
       " 'esfahanian',\n",
       " 'hakimi',\n",
       " 'backward',\n",
       " 'low[',\n",
       " 'descendant',\n",
       " 'frond',\n",
       " 'maximal',\n",
       " 'denote',\n",
       " 'disjoint',\n",
       " 'skeleton',\n",
       " 'cutvertex',\n",
       " 'subset',\n",
       " 'triconnected',\n",
       " 'vertices',\n",
       " 'vertexconnectivity',\n",
       " 'subgraph',\n",
       " 'maxflow',\n",
       " 'tarjan',\n",
       " 'num[',\n",
       " 'edgeconnectivity',\n",
       " 'spanning',\n",
       " 'lowpt',\n",
       " 'kammer',\n",
       " 'aubig',\n",
       " 'cactus',\n",
       " 'dfs',\n",
       " 'biconnected',\n",
       " 'undirected',\n",
       " 'lemma',\n",
       " 'cid']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
