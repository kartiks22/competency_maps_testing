{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "import contractions\n",
    "import google_list\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "import math\n",
    "from string import ascii_uppercase\n",
    "from string import ascii_lowercase\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim import corpora, models\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_csv('corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "corp = corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "#         \"\"\"Use the ToktokTokenizer to obtain tokens from the text\"\"\"\n",
    "    tokenizer = nltk.tokenize.toktok.ToktokTokenizer()\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(corpus):\n",
    "#         \"\"\"Obtain Tokens for each document in the corpus\"\"\"\n",
    "#     tokenizer = nltk.tokenize.toktok.ToktokTokenizer()\n",
    "    tokenized_doc = []\n",
    "    for doc in corpus:\n",
    "        tokens = tokenize(doc)\n",
    "        filtered_tokens = [w for w in tokens if len(w) > 2]\n",
    "        tokenized_doc.append(filtered_tokens)\n",
    "    return tokenized_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['tokens'] = get_tokens(corpus['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_tokens = corpus['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(doc_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in doc_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dict = copy.deepcopy(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dict.filter_extremes(no_below=30, no_above=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(filtered_dict) > 0:\n",
    "    dictionary = filtered_dict\n",
    "    corpus = [dictionary.doc2bow(text) for text in doc_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf = gensim.models.TfidfModel(corpus, dictionary=dictionary)\n",
    "# corpus = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = []\n",
    "umass_scores = []\n",
    "model_list = {}\n",
    "max_topic_clusters = 10\n",
    "metrics = pd.DataFrame()\n",
    "best_model = None\n",
    "best_model_clusters = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LDA with 10 topic(s)\n"
     ]
    }
   ],
   "source": [
    "for topics in range(10, max_topic_clusters + 1):\n",
    "    print(\"Running LDA with {0} topic(s)\".format(topics))\n",
    "    lm = gensim.models.LdaMulticore(corpus= corpus, num_topics=topics, id2word=dictionary, passes=100,\n",
    "                                    chunksize=2000, alpha='symmetric', eval_every=10,\n",
    "                                    random_state=42)\n",
    "    model_list[topics] = lm\n",
    "    \n",
    "    cm_1 = gensim.models.CoherenceModel(model=lm, texts=doc_tokens, dictionary=dictionary,coherence='c_v').get_coherence()\n",
    "    cm_2 = gensim.models.CoherenceModel(model=lm, corpus=corpus, dictionary=dictionary,coherence='u_mass').get_coherence()\n",
    "    lp = lm.log_perplexity(corpus)\n",
    "    cv_scores.append(cm_1)\n",
    "    umass_scores.append(cm_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(\n",
    "            {'topics': range(10, max_topic_clusters + 1),'cv_score': cv_scores,\n",
    "             'umass_score': umass_scores,'log_perplexity': lp})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric='cv_score'\n",
    "n_topics = metrics[metrics[metric] == metrics[metric].max()]['topics'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = model_list.get(n_topics)\n",
    "best_model_clusters = n_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.387*\"market\" + 0.056*\"perfect\" + 0.054*\"per\" + 0.053*\"equilibrium\" + 0.033*\"procedure\" + 0.019*\"happens\" + 0.016*\"minimum\" + 0.015*\"distinct\" + 0.014*\"limit\" + 0.013*\"claim\"\n",
      "Topic: 1 \n",
      "Words: 0.352*\"matrix\" + 0.047*\"computed\" + 0.038*\"approximation\" + 0.029*\"element\" + 0.028*\"bound\" + 0.025*\"proposed\" + 0.023*\"consists\" + 0.022*\"convergence\" + 0.021*\"claim\" + 0.021*\"write\"\n",
      "Topic: 2 \n",
      "Words: 0.008*\"experiment\" + 0.008*\"gain\" + 0.008*\"goal\" + 0.008*\"enough\" + 0.008*\"equally\" + 0.008*\"full\" + 0.008*\"difficult\" + 0.008*\"generate\" + 0.008*\"knowledge\" + 0.008*\"illustrated\"\n",
      "Topic: 3 \n",
      "Words: 0.287*\"degree\" + 0.060*\"parameter\" + 0.046*\"subset\" + 0.029*\"construct\" + 0.028*\"global\" + 0.027*\"edges\" + 0.026*\"bound\" + 0.023*\"element\" + 0.017*\"minimum\" + 0.016*\"cycle\"\n",
      "Topic: 4 \n",
      "Words: 0.445*\"web\" + 0.036*\"communication\" + 0.033*\"topic\" + 0.030*\"paper\" + 0.029*\"com\" + 0.024*\"global\" + 0.021*\"direction\" + 0.016*\"developed\" + 0.016*\"mind\" + 0.016*\"early\"\n",
      "Topic: 5 \n",
      "Words: 0.179*\"alternative\" + 0.147*\"minimum\" + 0.086*\"element\" + 0.069*\"structural\" + 0.036*\"subset\" + 0.022*\"contain\" + 0.021*\"satisfies\" + 0.019*\"consists\" + 0.019*\"associated\" + 0.019*\"complexity\"\n",
      "Topic: 6 \n",
      "Words: 0.122*\"public\" + 0.065*\"parameter\" + 0.064*\"convergence\" + 0.050*\"activity\" + 0.039*\"limit\" + 0.035*\"support\" + 0.034*\"learn\" + 0.029*\"knowledge\" + 0.027*\"evolution\" + 0.027*\"perfect\"\n",
      "Topic: 7 \n",
      "Words: 0.091*\"person\" + 0.063*\"experiment\" + 0.021*\"full\" + 0.020*\"arise\" + 0.020*\"enough\" + 0.019*\"happens\" + 0.018*\"receives\" + 0.018*\"suggests\" + 0.017*\"decide\" + 0.017*\"moreover\"\n",
      "Topic: 8 \n",
      "Words: 0.566*\"equilibrium\" + 0.029*\"highest\" + 0.025*\"incentive\" + 0.019*\"future\" + 0.016*\"knowledge\" + 0.015*\"gain\" + 0.014*\"perfect\" + 0.013*\"population\" + 0.012*\"act\" + 0.010*\"neither\"\n",
      "Topic: 9 \n",
      "Words: 0.185*\"population\" + 0.086*\"weak\" + 0.079*\"structural\" + 0.056*\"relationship\" + 0.047*\"cycle\" + 0.039*\"global\" + 0.032*\"claim\" + 0.025*\"edges\" + 0.024*\"area\" + 0.020*\"connection\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in best_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
